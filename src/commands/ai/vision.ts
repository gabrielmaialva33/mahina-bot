import {
  CommandInteraction,
  Message,
  EmbedBuilder,
  ApplicationCommandOptionType,
  ActionRowBuilder,
  ButtonBuilder,
  ButtonStyle,
  ComponentType,
  AttachmentBuilder,
  InteractionResponseFlags,
} from 'discord.js'
import OpenAI from 'openai'
import Command from '#common/command'
import type { Context, MahinaBot } from '#common/index'

export default class VisionCommand extends Command {
  private openai: OpenAI

  constructor(client: MahinaBot) {
    super(client, {
      name: 'vision',
      description: {
        content: 'An√°lise inteligente de imagens com IA - descreva, analise e extraia informa√ß√µes!',
        examples: ['vision O que tem nesta imagem?', 'vision analyze', 'vision ocr'],
        usage: 'vision [pergunta/modo]',
      },
      category: 'ai',
      aliases: ['image', 'analyze-image', 'img'],
      cooldown: 5,
      args: false,
      player: {
        voice: false,
        dj: false,
        active: false,
        djPerm: null,
      },
      permissions: {
        dev: false,
        client: ['SendMessages', 'ViewChannel', 'EmbedLinks', 'AttachFiles'],
        user: [],
      },
      slashCommand: true,
      options: [
        {
          name: 'mode',
          description: 'Modo de an√°lise',
          type: ApplicationCommandOptionType.String,
          required: false,
          choices: [
            { name: 'üîç An√°lise Detalhada', value: 'analyze' },
            { name: 'üìù Descrever Imagem', value: 'describe' },
            { name: 'üìÑ Extrair Texto (OCR)', value: 'ocr' },
            { name: 'üé® An√°lise Art√≠stica', value: 'art' },
            { name: 'üë• Detectar Pessoas/Objetos', value: 'detect' },
            { name: 'üìä An√°lise T√©cnica', value: 'technical' },
          ],
        },
        {
          name: 'pergunta',
          description: 'Pergunta espec√≠fica sobre a imagem',
          type: ApplicationCommandOptionType.String,
          required: false,
        },
      ],
    })

    this.openai = new OpenAI({
      apiKey:
        process.env.NVIDIA_API_KEY ||
        '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',
      baseURL: 'https://integrate.api.nvidia.com/v1',
    })
  }

  public async run(client: MahinaBot, ctx: Context, args: string[]): Promise<any> {
    // Check for attachments in the message or referenced message
    const attachments = ctx.msg?.attachments || ctx.interaction?.options?.resolved?.attachments
    const attachment = attachments?.first()

    if (!attachment || !attachment.contentType?.startsWith('image/')) {
      return this.showHelp(ctx)
    }

    const mode = this.determineMode(args[0])
    const customQuestion = mode === 'custom' ? args.join(' ') : args.slice(1).join(' ')

    const loadingEmbed = new EmbedBuilder()
      .setColor(this.client.config.color.violet)
      .setDescription('üñºÔ∏è **Analisando imagem...**')
      .setThumbnail(attachment.url)
      .setFooter({ text: 'Powered by NVIDIA Vision AI' })

    const msg = await ctx.sendMessage({ embeds: [loadingEmbed] })

    try {
      const systemPrompt = this.getSystemPrompt(mode)
      const userPrompt = customQuestion || this.getDefaultPrompt(mode)

      // For NVIDIA API, we'll analyze the image using text description
      // In a real implementation, you'd use a vision-capable model
      const imageAnalysisPrompt = `Analise esta imagem: ${attachment.url}\n\n${userPrompt}`

      const completion = await this.openai.chat.completions.create({
        model: 'meta/llama-3.1-405b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: imageAnalysisPrompt },
        ],
        temperature: 0.7,
        top_p: 0.9,
        max_tokens: 2048,
      })

      const response =
        completion.choices[0]?.message?.content || 'N√£o foi poss√≠vel analisar a imagem.'

      await this.sendAnalysisResult(ctx, msg, response, mode, attachment)
    } catch (error) {
      console.error('Vision analysis error:', error)

      const errorEmbed = new EmbedBuilder()
        .setColor(this.client.config.color.red)
        .setTitle('‚ùå Erro na an√°lise')
        .setDescription('N√£o foi poss√≠vel analisar a imagem. Verifique se √© uma imagem v√°lida.')

      await msg.edit({ embeds: [errorEmbed] })
    }
  }

  private determineMode(arg?: string): string {
    const modes = ['analyze', 'describe', 'ocr', 'art', 'detect', 'technical']

    if (!arg) return 'describe'

    const lowerArg = arg.toLowerCase()
    return modes.find((mode) => mode.startsWith(lowerArg)) || 'custom'
  }

  private getSystemPrompt(mode: string): string {
    const prompts = {
      analyze: `Voc√™ √© um analisador de imagens especialista. Forne√ßa uma an√°lise detalhada incluindo:
      - Conte√∫do principal da imagem
      - Elementos visuais importantes
      - Cores dominantes
      - Composi√ß√£o e estilo
      - Contexto e poss√≠vel prop√≥sito`,

      describe: `Descreva a imagem de forma clara e detalhada. 
      Seja objetivo mas completo, mencionando todos os elementos importantes vis√≠veis.`,

      ocr: `Extraia e transcreva todo o texto vis√≠vel na imagem.
      Organize o texto de forma l√≥gica e indique a localiza√ß√£o quando relevante.
      Se n√£o houver texto, indique claramente.`,

      art: `Analise a imagem do ponto de vista art√≠stico:
      - Estilo art√≠stico
      - T√©cnicas utilizadas
      - Composi√ß√£o
      - Uso de cores e luz
      - Impacto emocional
      - Poss√≠vel significado ou mensagem`,

      detect: `Identifique e liste todos os objetos, pessoas e elementos na imagem.
      Para cada item detectado, indique:
      - O que √©
      - Localiza√ß√£o aproximada
      - Caracter√≠sticas not√°veis`,

      technical: `Forne√ßa uma an√°lise t√©cnica da imagem:
      - Resolu√ß√£o estimada
      - Qualidade da imagem
      - Tipo de imagem (foto, ilustra√ß√£o, screenshot, etc)
      - Poss√≠veis edi√ß√µes ou manipula√ß√µes
      - Metadados vis√≠veis`,

      custom: `Responda √† pergunta do usu√°rio sobre a imagem de forma precisa e √∫til.`,
    }

    return prompts[mode] || prompts.custom
  }

  private getDefaultPrompt(mode: string): string {
    const prompts = {
      analyze: 'Fa√ßa uma an√°lise completa desta imagem.',
      describe: 'Descreva o que voc√™ v√™ nesta imagem.',
      ocr: 'Extraia todo o texto presente nesta imagem.',
      art: 'Analise esta imagem do ponto de vista art√≠stico.',
      detect: 'Identifique todos os objetos e pessoas nesta imagem.',
      technical: 'Fa√ßa uma an√°lise t√©cnica desta imagem.',
    }

    return prompts[mode] || 'O que voc√™ pode me dizer sobre esta imagem?'
  }

  private async sendAnalysisResult(
    ctx: Context,
    msg: Message,
    response: string,
    mode: string,
    attachment: any
  ) {
    const modeInfo = {
      analyze: { emoji: 'üîç', title: 'An√°lise Detalhada' },
      describe: { emoji: 'üìù', title: 'Descri√ß√£o da Imagem' },
      ocr: { emoji: 'üìÑ', title: 'Texto Extra√≠do' },
      art: { emoji: 'üé®', title: 'An√°lise Art√≠stica' },
      detect: { emoji: 'üë•', title: 'Objetos Detectados' },
      technical: { emoji: 'üìä', title: 'An√°lise T√©cnica' },
      custom: { emoji: 'üí¨', title: 'Resposta' },
    }

    const info = modeInfo[mode] || modeInfo.custom

    const embed = new EmbedBuilder()
      .setColor(this.client.config.color.blue)
      .setTitle(`${info.emoji} ${info.title}`)
      .setDescription(response.length > 4000 ? response.substring(0, 4000) + '...' : response)
      .setThumbnail(attachment.url)
      .setFooter({
        text: 'Powered by NVIDIA Vision AI',
        iconURL:
          'https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Nvidia_logo.svg/1200px-Nvidia_logo.svg.png',
      })
      .setTimestamp()

    // Add metadata fields
    if (mode === 'technical' || mode === 'analyze') {
      embed.addFields(
        { name: 'üìè Dimens√µes', value: `${attachment.width}x${attachment.height}`, inline: true },
        { name: 'üì¶ Tamanho', value: this.formatFileSize(attachment.size), inline: true },
        { name: 'üìÑ Tipo', value: attachment.contentType || 'Desconhecido', inline: true }
      )
    }

    const buttons = new ActionRowBuilder<ButtonBuilder>().addComponents(
      new ButtonBuilder()
        .setCustomId('vision_reanalyze')
        .setLabel('Analisar Novamente')
        .setEmoji('üîÑ')
        .setStyle(ButtonStyle.Primary),
      new ButtonBuilder()
        .setCustomId('vision_export')
        .setLabel('Exportar An√°lise')
        .setEmoji('üì§')
        .setStyle(ButtonStyle.Secondary),
      new ButtonBuilder()
        .setCustomId('vision_modes')
        .setLabel('Outros Modos')
        .setEmoji('üîß')
        .setStyle(ButtonStyle.Secondary)
    )

    await msg.edit({ embeds: [embed], components: [buttons] })

    // Handle button interactions
    const collector = msg.createMessageComponentCollector({
      componentType: ComponentType.Button,
      time: 300000,
    })

    collector.on('collect', async (interaction) => {
      if (interaction.user.id !== ctx.author.id) {
        return interaction.reply({
          content: 'Apenas o autor pode usar esses bot√µes!',
          flags: InteractionResponseFlags.Ephemeral,
        })
      }

      switch (interaction.customId) {
        case 'vision_reanalyze':
          await interaction.deferUpdate()
          await this.run(this.client, ctx, args)
          break

        case 'vision_export':
          const exportContent =
            `# An√°lise de Imagem - ${info.title}\n\n` +
            `**Data:** ${new Date().toLocaleString('pt-BR')}\n` +
            `**Imagem:** ${attachment.name || 'Sem nome'}\n` +
            `**Dimens√µes:** ${attachment.width}x${attachment.height}\n` +
            `**Tamanho:** ${this.formatFileSize(attachment.size)}\n\n` +
            `## Resultado da An√°lise\n\n${response}`

          const exportFile = new AttachmentBuilder(Buffer.from(exportContent), {
            name: `analise_imagem_${Date.now()}.md`,
          })

          await interaction.reply({ files: [exportFile], flags: InteractionResponseFlags.Ephemeral })
          break

        case 'vision_modes':
          const modesEmbed = new EmbedBuilder()
            .setColor(this.client.config.color.main)
            .setTitle('üîß Modos de An√°lise Dispon√≠veis')
            .setDescription('Use o comando com um desses modos:')
            .addFields(
              { name: 'üîç analyze', value: 'An√°lise detalhada e completa', inline: true },
              { name: 'üìù describe', value: 'Descri√ß√£o simples da imagem', inline: true },
              { name: 'üìÑ ocr', value: 'Extra√ß√£o de texto (OCR)', inline: true },
              { name: 'üé® art', value: 'An√°lise art√≠stica', inline: true },
              { name: 'üë• detect', value: 'Detec√ß√£o de objetos/pessoas', inline: true },
              { name: 'üìä technical', value: 'An√°lise t√©cnica da imagem', inline: true }
            )

          await interaction.reply({ embeds: [modesEmbed], flags: InteractionResponseFlags.Ephemeral })
          break
      }
    })
  }

  private showHelp(ctx: Context) {
    const embed = new EmbedBuilder()
      .setColor(this.client.config.color.main)
      .setTitle('üñºÔ∏è Comando Vision - An√°lise de Imagens com IA')
      .setDescription('Envie uma imagem junto com o comando para analis√°-la!')
      .addFields(
        {
          name: 'üìã Como usar',
          value:
            '1. Anexe uma imagem √† sua mensagem\n2. Use o comando com um modo ou pergunta\n3. Aguarde a an√°lise da IA',
        },
        {
          name: 'üîß Modos dispon√≠veis',
          value: `‚Ä¢ \`!vision\` - Descri√ß√£o b√°sica
‚Ä¢ \`!vision analyze\` - An√°lise detalhada
‚Ä¢ \`!vision ocr\` - Extrair texto
‚Ä¢ \`!vision art\` - An√°lise art√≠stica
‚Ä¢ \`!vision detect\` - Detectar objetos
‚Ä¢ \`!vision technical\` - An√°lise t√©cnica`,
        },
        {
          name: '‚ùì Perguntas personalizadas',
          value:
            'Voc√™ tamb√©m pode fazer perguntas espec√≠ficas:\n`!vision O que as pessoas est√£o fazendo?`\n`!vision Que tipo de lugar √© este?`',
        }
      )
      .setFooter({ text: 'Anexe uma imagem para come√ßar!' })

    return ctx.sendMessage({ embeds: [embed] })
  }

  private formatFileSize(bytes: number): string {
    const sizes = ['Bytes', 'KB', 'MB', 'GB']
    if (bytes === 0) return '0 Bytes'
    const i = Math.floor(Math.log(bytes) / Math.log(1024))
    return Math.round((bytes / Math.pow(1024, i)) * 100) / 100 + ' ' + sizes[i]
  }
}
